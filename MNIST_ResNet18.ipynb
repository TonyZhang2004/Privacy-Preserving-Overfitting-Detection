{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cedb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”µ Training ResNet18 (5 epochs)\n",
      "Epoch 1/5 | Loss: 0.1354 | Acc: 97.58% | Frobenius Norm: 113.71\n",
      "Epoch 2/5 | Loss: 0.0606 | Acc: 98.87% | Frobenius Norm: 115.05\n",
      "Epoch 3/5 | Loss: 0.0464 | Acc: 98.62% | Frobenius Norm: 116.76\n",
      "Epoch 4/5 | Loss: 0.0368 | Acc: 98.82% | Frobenius Norm: 118.72\n",
      "Epoch 5/5 | Loss: 0.0332 | Acc: 99.02% | Frobenius Norm: 121.34\n",
      "\n",
      "ðŸ”´ Training ResNet18 (50 epochs)\n",
      "Epoch 1/50 | Loss: 0.1319 | Acc: 98.12% | Frobenius Norm: 113.69\n",
      "Epoch 2/50 | Loss: 0.0596 | Acc: 98.57% | Frobenius Norm: 115.03\n",
      "Epoch 3/50 | Loss: 0.0462 | Acc: 98.88% | Frobenius Norm: 116.73\n",
      "Epoch 4/50 | Loss: 0.0382 | Acc: 98.72% | Frobenius Norm: 118.77\n",
      "Epoch 5/50 | Loss: 0.0338 | Acc: 98.94% | Frobenius Norm: 121.38\n",
      "Epoch 6/50 | Loss: 0.0284 | Acc: 98.99% | Frobenius Norm: 124.35\n",
      "Epoch 7/50 | Loss: 0.0276 | Acc: 98.81% | Frobenius Norm: 128.48\n",
      "Epoch 8/50 | Loss: 0.0218 | Acc: 98.78% | Frobenius Norm: 132.28\n",
      "Epoch 9/50 | Loss: 0.0197 | Acc: 98.99% | Frobenius Norm: 136.89\n",
      "Epoch 10/50 | Loss: 0.0227 | Acc: 99.00% | Frobenius Norm: 144.28\n",
      "Epoch 11/50 | Loss: 0.0160 | Acc: 99.02% | Frobenius Norm: 149.24\n",
      "Epoch 12/50 | Loss: 0.0141 | Acc: 99.16% | Frobenius Norm: 153.75\n",
      "Epoch 13/50 | Loss: 0.0136 | Acc: 99.39% | Frobenius Norm: 158.86\n",
      "Epoch 14/50 | Loss: 0.0170 | Acc: 99.37% | Frobenius Norm: 173.04\n",
      "Epoch 15/50 | Loss: 0.0096 | Acc: 99.36% | Frobenius Norm: 177.47\n",
      "Epoch 16/50 | Loss: 0.0123 | Acc: 99.30% | Frobenius Norm: 184.44\n",
      "Epoch 17/50 | Loss: 0.0078 | Acc: 99.30% | Frobenius Norm: 188.56\n",
      "Epoch 18/50 | Loss: 0.0093 | Acc: 99.28% | Frobenius Norm: 194.03\n",
      "Epoch 19/50 | Loss: 0.0095 | Acc: 99.34% | Frobenius Norm: 201.34\n",
      "Epoch 20/50 | Loss: 0.0072 | Acc: 99.20% | Frobenius Norm: 210.07\n",
      "Epoch 21/50 | Loss: 0.0081 | Acc: 99.30% | Frobenius Norm: 216.69\n",
      "Epoch 22/50 | Loss: 0.0056 | Acc: 99.36% | Frobenius Norm: 221.16\n",
      "Epoch 23/50 | Loss: 0.0067 | Acc: 99.35% | Frobenius Norm: 228.19\n",
      "Epoch 24/50 | Loss: 0.0070 | Acc: 99.42% | Frobenius Norm: 235.23\n",
      "Epoch 25/50 | Loss: 0.0052 | Acc: 99.19% | Frobenius Norm: 241.47\n",
      "Epoch 26/50 | Loss: 0.0051 | Acc: 99.43% | Frobenius Norm: 246.83\n",
      "Epoch 27/50 | Loss: 0.0058 | Acc: 99.39% | Frobenius Norm: 254.55\n",
      "Epoch 28/50 | Loss: 0.0058 | Acc: 99.39% | Frobenius Norm: 260.74\n",
      "Epoch 29/50 | Loss: 0.0048 | Acc: 99.40% | Frobenius Norm: 266.73\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_resnet18(num_classes=10):\n",
    "    model = models.resnet18(weights=None)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "def compute_frobenius_norm(model):\n",
    "    weights = [param for name, param in model.named_parameters() if 'weight' in name]\n",
    "    all_weights = torch.cat([w.flatten() for w in weights])\n",
    "    return torch.norm(all_weights, p=2).item()\n",
    "\n",
    "def train_model(model, optimizer, train_loader, test_loader, epochs=5, device='cpu'):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    train_loss, train_acc, test_acc, frob_norms = [], [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_train, total_train = 0, 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_train += (predicted == targets).sum().item()\n",
    "            total_train += targets.size(0)\n",
    "\n",
    "        epoch_train_loss = total_loss / len(train_loader)\n",
    "        epoch_train_acc = correct_train / total_train\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        correct_test, total_test = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_test += (predicted == targets).sum().item()\n",
    "                total_test += targets.size(0)\n",
    "\n",
    "        epoch_test_acc = correct_test / total_test\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        frob_norms.append(compute_frobenius_norm(model))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {epoch_train_loss:.4f} | \"\n",
    "              f\"Train Acc: {epoch_train_acc*100:.2f}% | Test Acc: {epoch_test_acc*100:.2f}% | \"\n",
    "              f\"Frobenius Norm: {frob_norms[-1]:.2f}\")\n",
    "\n",
    "    return train_loss, train_acc, test_acc, frob_norms\n",
    "\n",
    "# Data loading\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Train model (5 epochs)\n",
    "print(\"\\nðŸ”µ Training ResNet18 (5 epochs)\")\n",
    "model_normal = get_resnet18()\n",
    "optimizer_normal = optim.Adam(model_normal.parameters(), lr=0.001)\n",
    "normal_loss, normal_train_acc, normal_test_acc, normal_frob = train_model(\n",
    "    model_normal, optimizer_normal, train_loader, test_loader, epochs=5, device=device\n",
    ")\n",
    "\n",
    "# Train model (50 epochs)\n",
    "print(\"\\nðŸ”´ Training ResNet18 (50 epochs)\")\n",
    "model_overfit = get_resnet18()\n",
    "optimizer_overfit = optim.Adam(model_overfit.parameters(), lr=0.001)\n",
    "overfit_loss, overfit_train_acc, overfit_test_acc, overfit_frob = train_model(\n",
    "    model_overfit, optimizer_overfit, train_loader, test_loader, epochs=50, device=device\n",
    ")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, 6), normal_loss, label=\"Normal (5 epochs)\")\n",
    "plt.plot(range(1, 51), overfit_loss, label=\"Overfit (50 epochs)\")\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 6), normal_train_acc, label=\"Train Acc (5 epochs)\")\n",
    "plt.plot(range(1, 6), normal_test_acc, label=\"Test Acc (5 epochs)\")\n",
    "plt.plot(range(1, 51), overfit_train_acc, label=\"Train Acc (50 epochs)\")\n",
    "plt.plot(range(1, 51), overfit_test_acc, label=\"Test Acc (50 epochs)\")\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final Frobenius Norms:\\nðŸ”µ Normal: {normal_frob[-1]:.2f}\\nðŸ”´ Overfit: {overfit_frob[-1]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
